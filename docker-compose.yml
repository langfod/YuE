services:
  yue-exllamav2-interface:
    build: .
    image: yue-exllamav2-interface  # Docker image for YuE Interface, default was alissonpereiraanjos/yue-exllamav2-interface:latest
    container_name: YuE-exllamav2  # Name of the container
    # restart: unless-stopped  # Restart policy: always restart unless manually stopped
    ports:
      - "7860:7860"  # Map port 7860 (Gradio UI) to the host
      #- "8888:8888"  # Optional: Map an additional port (e.g., for other services)
    environment:
      - NVIDIA_VISIBLE_DEVICES=all  # Expose all GPUs
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility  # Enable CUDA support
      - DOWNLOAD_MODELS=YuE-s2-1B-general,YuE-s1-7B-anneal-en-cot,YuE-s1-7B-anneal-en-icl,YuE-upsampler # set to all to get all models. Replace "all" with specific model keys if needed.
                                                                                          # Example: DOWNLOAD_MODELS=YuE-s2-1B-general,YuE-s1-7B-anneal-en-cot
    volumes:
      - yue-exllama-models:/workspace/models  # Map the host's model directory to the container
      - yue-exllama-outputs:/workspace/outputs  # Map the host's output directory to the container
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]  # Enable GPU support (requires NVIDIA GPU and drivers)

volumes:
  yue-exllama-models:  # Define named volume
  yue-exllama-outputs:  # Define named volume
